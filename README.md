# ðŸ¤– Agentic RAG QA System â€” Multi-Format Document Intelligence

A production-inspired **Retrieval-Augmented Generation (RAG)** system that answers natural-language questions from documents across multiple formats â€” PDF, DOCX, PPTX, CSV, and TXT.

Unlike typical monolithic RAG pipelines, this system uses an **agent-based architecture inspired by the Model Context Protocol (MCP)** â€” where each stage of the pipeline is a separate, communicating agent. This makes the system modular, debuggable, and closer to how real production AI systems are designed.

---

## ðŸš© The Problem This Solves

Most RAG implementations are monolithic scripts â€” hard to debug, hard to extend, and far from production-ready.

This project answers: **what does a well-architected, agent-based RAG system actually look like in code?**

- You upload any combination of PDF, DOCX, PPTX, CSV, or TXT files
- The system parses, chunks, embeds, and indexes them automatically
- You ask questions in natural language
- Grounded, context-aware answers come back â€” with full traceability through structured agent messages

---

## âš¡ Key Features

- **Multi-format ingestion** â€” PDF, DOCX, PPTX, CSV, TXT parsed and normalised into a unified pipeline
- **Agent-based architecture** â€” Ingestion, Retrieval, and LLM Response agents with clean separation of concerns
- **MCP-style JSON message passing** â€” structured, traceable communication between agents
- **Semantic search** â€” sentence transformer embeddings + FAISS/Chroma vector store
- **Context-aware responses** â€” grounded LLM answers with retrieved chunks as context
- **Interactive Streamlit UI** â€” upload documents and query in real time
- **Configurable pipeline** â€” chunk size, overlap, top-k retrieval, and similarity threshold all tunable

---
## ðŸ“¸ Screenshots

### ðŸ”¹ Initial Setup
![Initial Setup](screenshots/initial_setup.png)

### ðŸ”¹ Creating Vector Store
![Create Vectorstore](screenshots/create_vectorstore.png)

### ðŸ”¹ Loading PDF
![Load PDF](screenshots/load_pdf.png)

### ðŸ”¹ Q&A Code Block
![Q&A Code](screenshots/qa_code.png)

### ðŸ”¹ Q&A Output in Streamlit
![Q&A Output](screenshots/qa_output.png)

---

## ðŸ“Š Performance

| Metric | Value |
|--------|-------|
| Supported formats | PDF, DOCX, PPTX, CSV, TXT |
| Evaluation accuracy | 85.7% (6/7 test cases) |
| Avg. retrieval latency | < 2s on local setup |
| Chunk size (default) | 500 tokens |
| Top-k retrieval (default) | 3 chunks |
| Vector store | Chroma (default) / FAISS |

---

## ðŸ— System Architecture
```
User â†’ Streamlit UI â†’ Coordinator Agent
           â”œâ”€â”€ Ingestion Agent   â†’ Parses, cleans & chunks documents
           â”œâ”€â”€ Retrieval Agent   â†’ Embeds query & retrieves top-k chunks
           â””â”€â”€ LLM Response Agent â†’ Generates grounded final response
```

Agents communicate via **MCP-style structured JSON messages** â€” every interaction is typed, traced, and logged.

### Example Agent Message
```json
{
  "type": "CONTEXT_RESPONSE",
  "sender": "RetrievalAgent",
  "receiver": "LLMResponseAgent",
  "trace_id": "abc-123",
  "payload": {
    "top_chunks": ["..."],
    "query": "What are the KPIs?"
  }
}
```

---

## ðŸ§° Tech Stack

| Component | Tool |
|-----------|------|
| UI | Streamlit |
| LLM | OpenAI / HuggingFace |
| Embeddings | Sentence Transformers |
| Vector Store | FAISS / Chroma |
| File Parsing | PyMuPDF, python-docx, pandas, python-pptx |
| Message Protocol | MCP-inspired custom JSON |

---

## ðŸš€ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/KritikaK21/agentic-rag-qa.git
cd agentic-rag-qa
```

### 2. Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate      # Mac/Linux
venv\Scripts\activate         # Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Set up environment variables
Create a `.env` file in the root directory:
```
OPENAI_API_KEY=your_key_here
```

### 5. Run the app
```bash
streamlit run app.py
```

---

## ðŸ” Retrieval Pipeline
```
Upload â†’ Parse â†’ Chunk â†’ Embed â†’ Store in FAISS/Chroma
                                        â†“
Query â†’ Embed â†’ Similarity Search â†’ Top-k Chunks â†’ LLM â†’ Answer
```

**Configurable parameters:**
- `CHUNK_SIZE` â€” token size per chunk (default: 500)
- `CHUNK_OVERLAP` â€” overlap between chunks (default: 50)
- `TOP_K` â€” number of chunks retrieved per query (default: 5)
- `SIMILARITY_THRESHOLD` â€” minimum similarity score to include a chunk

---

## ðŸ’¡ Why Agentic Over Monolithic?

Most RAG tutorials give you a single script. That works for demos â€” not for production.

| | Monolithic RAG | Agentic RAG (This Project) |
|---|---|---|
| Debugging | Hard â€” one big pipeline | Easy â€” isolate any agent |
| Extensibility | Risky changes | Swap agents independently |
| Observability | Limited | Full message tracing |
| Production readiness | Low | High |

---

## ðŸ§ª Example Queries to Try

- *"Summarise the key findings across all uploaded documents"*
- *"What KPIs are mentioned in the reports?"*
- *"Extract all financial metrics from the uploaded files"*
- *"What recommendations are discussed across these documents?"*

---

## ðŸ”® Roadmap

- [ ] Deploy on Hugging Face Spaces
- [ ] Add persistent chat history
- [ ] LangGraph integration for advanced agent orchestration
- [ ] Redis/Kafka message bus for async agent communication
- [ ] Evaluation dashboard with retrieval accuracy metrics
- [ ] Authentication and multi-user support

---

## ðŸ™‹ About

Built by **Kritika Aggarwal**
- ðŸ™ GitHub: [KritikaK21](https://github.com/KritikaK21)
- ðŸ’¼ LinkedIn: [kritika-aggarwal-734997249](https://linkedin.com/in/kritika-aggarwal-734997249/)

---

## ðŸ“„ License

MIT License â€” feel free to use, modify and build on this.

